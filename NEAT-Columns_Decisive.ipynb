{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file controls the neuroevolution agent in a \"decisive\" way, i.e., by only feeding the agent's neural network with the actionable states of the board to minimize the need to run the neural network and therefore computational effort.\n",
    "\n",
    "This code is by no means perfect, but it does produce agents with reasonably serviceable play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T03:52:57.691266Z",
     "start_time": "2019-10-24T03:52:57.688261Z"
    }
   },
   "outputs": [],
   "source": [
    "# play the game directly ('X' to roll gems; arrow keys to move, Esc to close)\n",
    "# !python -m retro.examples.interactive --game Columns-Genesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T17:30:17.188550Z",
     "start_time": "2019-10-27T17:30:16.371391Z"
    }
   },
   "outputs": [],
   "source": [
    "## %matplotlib auto\n",
    "# import relevant libraries\n",
    "import retro \n",
    "import numpy as np \n",
    "import cv2\n",
    "import neat\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "from scipy.ndimage.measurements import label as sp_label\n",
    "# ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#set a random seed\n",
    "random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T17:30:17.208550Z",
     "start_time": "2019-10-27T17:30:17.192553Z"
    }
   },
   "outputs": [],
   "source": [
    "def rescale_grays():\n",
    "    '''\n",
    "    Remap grayscale image to new, higher contrast values\n",
    "    \n",
    "        input: (N/A)\n",
    "\n",
    "       output: rescale_map (NumPy array): color mapping for use in preprocessing\n",
    "    \n",
    "    called by: eval_genomes\n",
    "    '''    \n",
    "    \n",
    "    ######## uncomment block below to test standalone function ########\n",
    "#     game, state = 'Columns-Genesis', 'Arcade.Easy.Level0'\n",
    "#     # specify type of retro environment observation space via index of below list\n",
    "#     input_type_index = 0 \n",
    "#     # specify observation type\n",
    "#     input_types = [retro.Observations.IMAGE, retro.Observations.RAM]\n",
    "#     # create the retro environment for the chosen game, including starting state\n",
    "#     env = retro.make(game,state,obs_type=input_types[input_type_index],use_restricted_actions=retro.Actions.ALL            )\n",
    "#     ob = env.reset()\n",
    "    ######## uncomment block above to test standalone function ########\n",
    "    ob = env.reset()\n",
    "    # color mapping start and end states to improve contrast and homogenize colors\n",
    "    colors =     np.array([192,156,138, 62,166, 90, 92, 46,128,121,69,59])\n",
    "    new_colors = np.array([202,202,172,172,142,142,112,112, 82, 82,52,52])\n",
    "    # initialize the mapping array\n",
    "    reshade_map = np.zeros(256, dtype=ob.dtype) \n",
    "    # populate the display mapping array\n",
    "    reshade_map[colors] = new_colors\n",
    "    # add 1 unit of 'wiggle room'\n",
    "    reshade_map = reshade_map + np.roll(reshade_map, 1) \n",
    "#     reshade_map[0]=0; reshade_map[-1]=0\n",
    "    # return final color mapping\n",
    "#     print(' ran rescale_grays to make map with type', type(reshade_map))\n",
    "    return reshade_map\n",
    "\n",
    "######## uncomment below line to test standalone function ########\n",
    "# rescale_grays()\n",
    "\n",
    "# index guide for mapping array:\n",
    "#   0              3              6              9              12 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T17:30:17.672643Z",
     "start_time": "2019-10-27T17:30:17.656646Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_image(ob_img, map, dims=np.array([8, 208, 16, 96]), shrink=8):\n",
    "    '''\n",
    "     input: ob_img (NumPy array): image to be processed\n",
    "            map(NumPy array): remapping of grayscale to improve contrast for the \n",
    "            neural net input\n",
    "            dims (NumPy array): dimensions of cropped observation frame\n",
    "            shrink (int): shrink factor by which to rescale image\n",
    "    output: prepped_image (NumPy array):\n",
    "    \n",
    "    called by: eval_genomes\n",
    "    '''\n",
    "# prepare a scaled image for rendering of final observation\n",
    "    sc_dims = dims/shrink\n",
    "    \n",
    "    # apply color conversion (quirk of OpenCV)\n",
    "    img  = cv2.cvtColor(ob_img, cv2.COLOR_BGR2GRAY)\n",
    "#             if frame == 1:\n",
    "#                 print(f'initial input_img: {input_img.shape}')\n",
    "    # crop the image via NumPy slicing (dims indices defined above)\n",
    "    img = img[dims[0]:dims[0]+dims[1], dims[2]:dims[2]+dims[3]]\n",
    "#             if frame == 1:\n",
    "#                 print(f'cropped input_img: {input_img.shape}')\n",
    "    # rescale to minimum dimensions that accommodate block cycling animation\n",
    "    img  = cv2.resize(img, (int((sc_dims[3])/2), int(sc_dims[1])))\n",
    "#             if frame == 1:\n",
    "#                 print(f'final input_img: {input_img.shape}')\n",
    "    # remap the colors to homogenize the jewel colorings\n",
    "    resh_img = map[img]\n",
    "    # throw out now-unnecessary vertical resolution\n",
    "    prepped_image = resh_img[::2]      \n",
    "#     print('ran process_image to produce: \\', prepped_image)    \n",
    "    return prepped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T17:30:18.300798Z",
     "start_time": "2019-10-27T17:30:18.268788Z"
    }
   },
   "outputs": [],
   "source": [
    "def col_isle_fit_calc(image_array, col_hts_i, isle_sizes_i):\n",
    "    '''\n",
    "     Calculate column height penalty and island bonus for provided array and update\n",
    "     initial values for the next calculation\n",
    "     \n",
    "        input: image_array (NumPy array): processed image of current game state \n",
    "               col_hts_i (NumPy array): initial state of column heights \n",
    "               isle_sizes_i (NumPy array): initial state of island sizes \n",
    "\n",
    "       output: col_pen (float): column penalty term associated with provided game state \n",
    "               isle_bonus (float): isle bonus term associated with provided game state\n",
    "               col_hts_i (NumPy array): init. state of col. heights for next iteration \n",
    "               isle_sizes_i (NumPy array): init. state of isle sizes for next iteration\n",
    "            \n",
    "    called by: \n",
    "    '''\n",
    "    # define valid connection structure for column labeling\n",
    "    c_valid_conns = np.array((0,1,0,0,1,0,0,1,0,), dtype=np.int).reshape((3,3))\n",
    "    # define valid connection structure for island labeling\n",
    "    i_valid_conns = np.append(np.append(np.zeros(9),np.ones(9)),np.zeros(9)).reshape(3,3,3)\n",
    "    # initialize index array for color-broadcasted game state\n",
    "    ind_grid = np.indices((7,13,6))     \n",
    "    # match range of colors to range of label outputs\n",
    "    unit_img = np.where(image_array == 0, 0, (image_array - 22)/30)\n",
    "    \n",
    "    ######## column penalty calculation ########\n",
    "    \n",
    "    # c_ncomponents is a simple count of the conected columns in labeled\n",
    "    columns, c_ncomponents = sp_label(unit_img, c_valid_conns)\n",
    "#     print(columns)\n",
    "\n",
    "    # throw out the falling block with .isin(x,x[-1]) combined with... \n",
    "    # the mask nonzero(x) \n",
    "    drop_falling = np.isin(columns, columns[-1][np.nonzero(columns[-1])])\n",
    "    col_hts = drop_falling.sum(axis=0)\n",
    "#     print(f'col_hts {col_hts}')\n",
    "\n",
    "    # calculate differentials for the (grounded) column heights\n",
    "    d_col_hts = np.sum(col_hts - col_hts_i)\n",
    "#     print(f'col_hts {col_hts} - col_hts_i {col_hts_i} ===> d_col_hts {d_col_hts}')\n",
    "\n",
    "    # set col_hts_i to current col_hts for next evaluation\n",
    "    col_hts_i = col_hts\n",
    "    \n",
    "    # calculate penalty/bonus function\n",
    "    col_pen = np.where(d_col_hts > 0, (col_hts**4 - 3**4), 0).sum()           \n",
    "#     if col_pen !=0:\n",
    "#         print(f'col_pen: {col_pen}')\n",
    "\n",
    "    ######## end column penalty calculation ########\n",
    "\n",
    "    ######## color island bonus calculation ########\n",
    "    \n",
    "    # mask the unit_img to remove the falling block\n",
    "    isle_img = drop_falling * image_array\n",
    "#             print(isle_img)\n",
    "\n",
    "    # broadcast the game board to add a layer for each color\n",
    "    isle_imgs = np.broadcast_to(isle_img,(7,*isle_img.shape))\n",
    "    \n",
    "    # define a mask to discriminate on color in each layer\n",
    "    isle_masked = isle_imgs*[isle_imgs==ind_grid[0]]\n",
    "    \n",
    "    # reshape the array to return to 3 dimensions\n",
    "    isle_masked = isle_masked.reshape(isle_imgs.shape)\n",
    "    \n",
    "    # generate the isle labels\n",
    "    isle_labels, isle_ncomps = sp_label(isle_masked, i_valid_conns)\n",
    "    \n",
    "    # determine the island sizes (via return_counts) for all the unique labels\n",
    "    isle_inds, isle_sizes = np.unique(isle_labels, return_counts=True)\n",
    "    \n",
    "    # zero out isle_sizes[0] to remove spike for background (500+ for near empty board)\n",
    "    isle_sizes[0] = 0\n",
    "    \n",
    "    # evaluate difference to determine whether bonus applies\n",
    "    if isle_sizes_i.sum() != isle_sizes.sum():\n",
    "        \n",
    "    # calculate bonus for all island sizes ater throwing away the 0 count\n",
    "        isle_bonus = (isle_sizes**3).sum()\n",
    "        \n",
    "    else:\n",
    "        isle_bonus = 0\n",
    "#             if isle_bonus != 0:\n",
    "#                 print(f'isle_bonus:{isle_bonus} isle_avgs_i: {isle_sizes_i.sum()}  isle_avgs {isle_sizes.sum()}')\n",
    "\n",
    "    # update the size distribution from the previous frame\n",
    "    isle_sizes_i = isle_sizes\n",
    "    ######## color island bonus calculation ########\n",
    "    \n",
    "#     print('col_isle_fit_calc to generate: ', col_pen, isle_bonus, col_hts_i, isle_sizes_i)\n",
    "    return col_pen, isle_bonus, col_hts_i, isle_sizes_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T17:30:18.900937Z",
     "start_time": "2019-10-27T17:30:18.869032Z"
    }
   },
   "outputs": [],
   "source": [
    "def score_future_states(image_array, col_scale, isle_scale):\n",
    "    '''\n",
    "     input: image_array (NumPy array): processed image of current game state\n",
    "            col_scale (float): scaling factor for column penalty (should be < 0)\n",
    "            isle_scale (float/int): scaling factor for isle bonus\n",
    "    \n",
    "    output: future_state_scores (NumPy array): evaluation values of future possible states\n",
    "            evaluations are based on the scaled column penalty and island bonus \n",
    "            fitness terms \n",
    "    \n",
    "    called by: eval_genomes\n",
    "    '''\n",
    "\n",
    "    # match range of colors to range of label outputs\n",
    "    unit_img = np.where(image_array == 0, 0, (image_array - 22)/30)\n",
    "\n",
    "    # isolate the falling block\n",
    "    falling = unit_img[:3,3] \n",
    "#     print('original state of falling: ', falling)\n",
    "\n",
    "    # capture permutations and transpose to retain original orientation of results\n",
    "    falling_perms = np.append(np.append(falling, np.roll(falling,1)), \n",
    "                             np.roll(falling,-1)                    ).reshape((3,3)).T\n",
    "#     print('falling permutations array: \\n', falling_perms)\n",
    "\n",
    "    # for this function, dropping the falling brick always happens in one place\n",
    "    image_array[:3,3] = 0  \n",
    "    \n",
    "    drop_falling = np.where(np.isnan(image_array/image_array), 0, image_array/image_array)\n",
    "    \n",
    "    # strip the falling block from the base array\n",
    "    future_stub  = drop_falling * unit_img\n",
    "    # broadcast the stub array to the third dimension to prepare to recieve permutations\n",
    "    future_stubs = np.broadcast_to(future_stub,(18,*future_stub.shape))\n",
    "#     print('shape of future_stubs:', future_stubs.shape)\n",
    "\n",
    "    # find indices of tops of each column\n",
    "#     print('drop_falling array: \\n', drop_falling)\n",
    "    # col_tops = np.where(drop_falling.sum(axis=0) == 0, drop_falling.shape[0], \n",
    "    #                     np.argmax(drop_falling, axis=0)                 )\n",
    "    col_tops = 13-drop_falling.sum(axis=0)\n",
    "#     print('col_tops:', col_tops)\n",
    "    \n",
    "#     print('falling_perms: \\n', falling_perms)\n",
    "#     print('future_stub: \\n', future_stub)\n",
    "\n",
    "    future_states = future_stubs.copy()\n",
    "\n",
    "    future_state_scores = np.zeros(18)\n",
    "\n",
    "    for i in range(18):\n",
    "        chi = np.zeros(6)\n",
    "        isi = np.zeros(1)\n",
    "\n",
    "        row_bottom_target = int(col_tops[i//3])\n",
    "#         print(row_bottom)\n",
    "        row_top_target = row_bottom_target-3\n",
    "#         print(row_top)\n",
    "        column_target = i//3\n",
    "#         print(column_target)\n",
    "        perm_target = i%3\n",
    "#         print(perm_index)\n",
    "        try:\n",
    "            future_states[i, row_top_target:row_bottom_target, \n",
    "                          column_target] = falling_perms[:, perm_target]\n",
    "\n",
    "            cp,ib,chi,isi = col_isle_fit_calc(future_states[i].reshape(future_stub.shape),chi,isi)\n",
    "\n",
    "            future_state_scores[i] = cp * col_scale + ib * isle_scale\n",
    "\n",
    "        #if the block won't fit in a column\n",
    "        except ValueError:\n",
    "            future_state_scores[i] = -999999999\n",
    "            \n",
    "    # if a column gets too high and blocks off those between it and the edge    \n",
    "    if future_state_scores[3]   == -999999999:\n",
    "        # give the net a \"game over\"-level penalty for that state\n",
    "        future_state_scores[0:3]   = -999999999\n",
    "    if future_state_scores[6]   == -999999999:\n",
    "        future_state_scores[0:6]   = -999999999\n",
    "    if future_state_scores[12] == -999999999:\n",
    "        future_state_scores[15:]   = -999999999\n",
    "        \n",
    "    #     print(f'test_stubs layer {i}: \\n', test_stubs[i])\n",
    "#     print('future state scores:', future_state_scores)\n",
    "    return future_state_scores\n",
    "\n",
    "# img = np.zeros((13,6))\n",
    "# img[5: ,0] = np.random.randint(1,7, size=(8) )\n",
    "# img[2: ,1] = np.random.randint(1,7, size=(11))\n",
    "# img[5: ,2] = np.random.randint(1,7, size=(8) )\n",
    "# img[7: ,3] = np.random.randint(1,7, size=(6) )\n",
    "# img[0: ,5] = np.random.randint(1,7, size=(13))\n",
    "# img[0:3,3] = np.random.randint(1,7, size=(3) )\n",
    "\n",
    "# score_future_states(img,-0.2,30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T17:30:19.865139Z",
     "start_time": "2019-10-27T17:30:19.813124Z"
    }
   },
   "outputs": [],
   "source": [
    "def provide_action(nn_choice, seq_index):\n",
    "    '''\n",
    "     input: nn_choice (int): selected action from the neural net\n",
    "            seq_index  (int): v\n",
    "\n",
    "    output: stepInput (list): multibinary list of button presses for the next frame \n",
    "                              of the game\n",
    "\n",
    "    called by: eval_genomes\n",
    "    '''\n",
    "\n",
    "    # actions (length 12)\n",
    "    #        c1       u d l r    c2\n",
    "    down  = [0,0,0,0, 0,1,0,0, 0,0,0,0]\n",
    "    left  = [0,0,0,0, 0,0,1,0, 0,0,0,0]\n",
    "    right = [0,0,0,0, 0,0,0,1, 0,0,0,0]\n",
    "    C1    = [1,0,0,0, 0,0,0,0, 0,0,0,0]\n",
    "    C2    = [0,0,0,0, 0,0,0,0, 0,1,0,0]\n",
    "    nil   = [0,0,0,0, 0,0,0,0, 0,0,0,0]\n",
    "\n",
    "    # action sequences (length 15)\n",
    "    #          0            2           4           6 \n",
    "    #                 8          10          12          14 \n",
    "    a_0 = [ left,  left, left, down, down, down, down, \n",
    "            down,  down, down, down, down, down,   nil, nil]\n",
    "    a_1 = [ left,  left, down, down, down, down, down,\n",
    "            down,  down, down, down, down,  nil,  nil,  nil]\n",
    "    a_2 = [ left,  down, down, down, down, down, down,\n",
    "            down,  down, down, down,  nil,  nil,  nil,  nil]\n",
    "    a_3 = [ down,  down, down, down, down, down, down,\n",
    "            down,  down, down,  nil,  nil,  nil,  nil,  nil]\n",
    "    a_4 = [right,  down, down, down, down, down, down,\n",
    "            down,  down, down, down,  nil,  nil,  nil,  nil]\n",
    "    a_5 = [right, right, down, down, down, down, down,\n",
    "            down,  down, down, down, down,  nil,  nil,  nil]\n",
    "\n",
    "    b_0 = [ left,  left, left,   C1, down, down, down,\n",
    "            down,  down, down, down, down, down, down,  nil]\n",
    "    b_1 = [ left,  left,   C1, down, down, down, down,\n",
    "            down,  down, down, down, down, down,  nil,  nil]\n",
    "    b_2 = [ left,    C1, down, down, down, down, down,\n",
    "            down,  down, down, down, down,  nil,  nil,  nil]\n",
    "    b_3 = [ left,  down, right,  C1, down, down, down, down, down, down,\n",
    "            down,  down, down, down,  nil,  nil,  nil,  nil]\n",
    "    b_4 = [right,    C1, down, down, down, down, down,\n",
    "            down,  down, down, down, down,  nil,  nil,  nil]\n",
    "    b_5 = [right, right,   C1, down, down, down, down,\n",
    "            down,  down, down, down, down, down,  nil,  nil]\n",
    "\n",
    "#     c_0 = [ left,  left, left,   C1, C1, nil, nil, nil, nil, nil, \n",
    "#            nil, nil, nil, nil, nil, C2, C2]\n",
    "    c_0 = [ left,  left, left,   C1,   C1,  nil,  nil,  nil,\n",
    "             nil,   nil,  nil,  nil,  nil,  nil,  nil,   C2,  C2]\n",
    "    c_1 = [ left,  left,   C1,   C1,  nil,  nil,  nil,\n",
    "             nil,   nil,  nil,  nil,  nil,  nil,  nil,   C2,  C2]\n",
    "    c_2 = [ left,   C1,   C1,  nil,  nil,  nil,\n",
    "             nil,   nil,  nil,  nil,  nil,  nil,  nil,   C2,  C2]\n",
    "    c_3 = [ left,   down, right, C1,   C1,   nil,  nil,  nil,\n",
    "             nil,   nil,  nil,  nil,  nil,  nil,  nil, down, C2]\n",
    "    c_4 = [right,   C1,   C1,  nil,  nil,  nil,\n",
    "             nil,   nil,  nil,  nil,  nil,  nil,  nil,   C2,  C2]\n",
    "    c_5 = [right, right,   C1,   C1,  nil,  nil,  nil,\n",
    "             nil,   nil,  nil,  nil,  nil,  nil,  nil,   C2,  C2]\n",
    "    # sequence options (length 18)                 \n",
    "    choices = [a_0, a_1, a_2, a_3, a_4, a_5, \n",
    "               b_0, b_1, b_2, b_3, b_4, b_5, \n",
    "               c_0, c_1, c_2, c_3, c_4, c_5 ]\n",
    "    # if the inputs are not in actionable ranges\n",
    "    if (nn_choice not in range(0,len(choices))) or (seq_index not in range(0,len(c_0)+1)):\n",
    "        # take no action\n",
    "        return down\n",
    "    # otherwise set stepInput appropriately\n",
    "    if seq_index%4== 0: \n",
    "        stepInput = choices[nn_choice][int(seq_index//4)]\n",
    "    else:\n",
    "        stepInput = nil\n",
    "    return stepInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-27T17:30:34.501440Z",
     "start_time": "2019-10-27T17:30:34.457429Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval_genomes(genomes, config, slowdown='', render=True, cv2_disp=True):\n",
    "    '''\n",
    "     input: genomes (neat.genome.DefaultGenome): genome objects from neat.population.\n",
    "                                                 Population to be evaluated\n",
    "            config (neat.config.Config): neat configuration container\n",
    "            slowdown (float or int): slow down each frame of game advancement by \n",
    "                                     the number of seconds specified\n",
    "            render (bool): indicate whether to render the game via gym-retro\n",
    "            cv2_disp (bool): indicate whether to display neural net input via cv2\n",
    "           \n",
    "    output: [N/A or fitness(float)]\n",
    "    \n",
    "    called by: neat.population.Population.run\n",
    "    '''\n",
    "    # initialize genome counter and action frequency\n",
    "    genome_counter = 0\n",
    "    # define shrink factor and pre-shrink cropped image dimensions\n",
    "    shrink, dims = 8, np.array([8, 208, 16, 96])\n",
    "    # define size of processed game image after crop and shrink\n",
    "    sc_dims = dims/shrink\n",
    "    # define reward drought counter limit\n",
    "    seq_index = 0\n",
    "    # define reward scaling factors\n",
    "    col_scale, isle_scale, match_scale, wild_scale = -0.2, 30, 500, 5\n",
    "    rescale_gray_map = rescale_grays()\n",
    "\n",
    "    # reset the environment to initialize gym retro\n",
    "    ob = env.reset()    \n",
    "    \n",
    "    # for each member of the population:\n",
    "    for genome_id, genome in genomes:\n",
    "\n",
    "        # increment genome counter\n",
    "        genome_counter += 1\n",
    "      \n",
    "        # initialize a few tracking variables\n",
    "        fitness, d_fitness, seq_counter, nn_choice, frame = 0, 0, -3, 3, 0\n",
    "        # column height and island size starting states to feed col_isle_fit_calc\n",
    "        cols_i, isles_i = np.zeros(6), np.array(0)\n",
    "        # initialize being done as false\n",
    "        done = False\n",
    "        \n",
    "        # create the neural net\n",
    "        net = neat.nn.recurrent.RecurrentNetwork.create(genome, config)\n",
    "\n",
    "        # reset the environment\n",
    "        ob = env.reset()\n",
    "        \n",
    "        # if viewing the neural net input directly is desired\n",
    "        if cv2_disp == True:\n",
    "            # make an OpenCV window\n",
    "            cv2.namedWindow('Decisive play', cv2.WINDOW_NORMAL)\n",
    "        \n",
    "        # begin tracking of cycle time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # while done is not True, i.e., the game is running\n",
    "        while not done:           \n",
    "            # open a render window to follow the action if requested\n",
    "            if render == True:\n",
    "                env.render()\n",
    "            # delay each frame for slowdown seconds if requested\n",
    "            if slowdown != '':\n",
    "                time.sleep(slowdown)\n",
    "            # increment the frame counter\n",
    "            frame += 1\n",
    "#             print('Frame', frame)\n",
    "            # process the image to feed the neural net\n",
    "            resc_img = process_image(ob, rescale_gray_map)\n",
    "            # show the cv2 window to follow the game state if requested \n",
    "            if cv2_disp == True:\n",
    "                cv2.imshow('Decisive play', resc_img)\n",
    "                cv2.waitKey(1)   \n",
    "\n",
    "\n",
    "            # evaluate column height penalty and color island bonus \n",
    "            col_pen, isle_bonus, cols_i, isles_i = col_isle_fit_calc(resc_img, cols_i, isles_i)\n",
    "\n",
    "            # build the input to the neural net\n",
    "            img_array = np.ravel(resc_img)\n",
    "            \n",
    "            if np.all(resc_img[0:3,3]) != 0: #and seq_counter == 0:\n",
    "#                 print(np.all(resc_img[0:3,3]) != 0 , \"seq_counter\", seq_counter)\n",
    "                if seq_counter == 0:\n",
    "                    # pre-score the future states when the current block is placed\n",
    "                    future_scores = score_future_states(resc_img, col_scale, isle_scale)\n",
    "\n",
    "                    # concatenate future scores with the game board state at evaluation\n",
    "                    nnInput = np.append(d_fitness, np.append(future_scores, img_array))\n",
    "\n",
    "                    # let neural net do its thing on input and generate action \n",
    "                    nnOutput = np.array(net.activate(nnInput))\n",
    "#                     print('nnOutput:', nnOutput)\n",
    "                    nn_choice = np.random.choice(np.ravel(np.indices(nnOutput.shape).reshape(nnOutput.shape)\n",
    "                                                 *[nnOutput==np.max(nnOutput)]))\n",
    "#                     nn_choice = 11\n",
    "                    # apply column penalty to fitness\n",
    "                    d_fitness += float(col_pen) * col_scale\n",
    "                    # apply scaled isle creation bonus to fitness\n",
    "                    d_fitness += float(isle_bonus) * isle_scale\n",
    "#                     print([nnOutput==np.max(nnOutput)])\n",
    "\n",
    "#                     print('choice',  nn_choice)\n",
    "                        #\n",
    "            stepInput = provide_action(nn_choice, seq_counter)\n",
    "            # if frame = 1 or 2...\n",
    "            if frame <= 3:\n",
    "                # .. press down once (total twice) to fully expose the falling block\n",
    "                stepInput = [0, 0, 0, 0,  0, 1, 0, 0,  0, 0, 0, 0]\n",
    "\n",
    "#             print('stepInput', stepInput, 'seq_counter', seq_counter )\n",
    "            seq_counter += 1\n",
    "#                         print('Frame', frame, 'NN output:', nnOutput)\n",
    "#                         print('nn', time.time() - start_time, 's'); start_time = time.time()\n",
    "                \n",
    "        #             print('env step:', time.time() - start_time, 's'); start_time = time.time()\n",
    "            # feed the specified action to the emulator and capture outputs\n",
    "#             print('Frame', frame, 'action:', step_input)\n",
    "            ob, rew, done, info = env.step(stepInput)\n",
    "            # store score separately for reporting because f-strings are persnickety\n",
    "            step_score = info['score'] \n",
    "            # if a new block is fully visible\n",
    "            if np.all(resc_img[0:3,3]) != 0 and seq_counter > 3:\n",
    "                #reset sequence counter\n",
    "                seq_counter = 0\n",
    "            # if a reward is earned, i.e., score goes up\n",
    "            if (rew > 1):\n",
    "                # when removing gems:\n",
    "                if (rew != 10000):\n",
    "                    # apply scaled reward to fitness \n",
    "                    d_fitness += rew * match_scale\n",
    "                # when wildcard/magic block hits bottom:\n",
    "                elif rew == 10000:\n",
    "                    # apply scaled reward to fitness\n",
    "                    d_fitness += rew * wild_scale\n",
    "            # when pressing down to simply speed play:\n",
    "            else:    \n",
    "                # add the minor 'down' bonus to the fitness when it occurs\n",
    "                d_fitness += rew    \n",
    "\n",
    "\n",
    "            # add the fitness differential to the overall fitness\n",
    "            fitness += d_fitness\n",
    "            \n",
    "            # when a significant reward is earned...\n",
    "            if rew >= 30:\n",
    "                # ... give status update\n",
    "                print(f\"Frame {frame}: Earned {rew} reward.  Score: {step_score}  \\\n",
    "                      Fitness change: {d_fitness:0.3f}\")\n",
    "\n",
    "        # once out of the while loop, i.e., when the run is done\n",
    "        # ... print out the high-level results...\n",
    "        print(f'ID:{genome_id} S/N: {genome_counter} Final frame: {frame} \\\n",
    "              Fitness: {fitness:0.3f} Score: {step_score}')\n",
    "        # ... and the game over indicator\n",
    "        print(f'                             ****** }}}}>>>>>ID \\\n",
    "                  {genome_id} GAME OVER after {(time.time() - start_time):.3f} \\\n",
    "                  s <<<<<{{{{ ******'                                           )\n",
    "        \n",
    "        # save final fitness to genome_id's fitness attribute \n",
    "        genome.fitness = fitness\n",
    "        # return fitness to the parallel.ParallelEvaluator (Population.run ignores)\n",
    "#         return fitness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T19:26:57.382076Z",
     "start_time": "2019-10-25T19:26:57.377076Z"
    }
   },
   "outputs": [],
   "source": [
    "# close the render window when finished\n",
    "try:\n",
    "    env.render(close=True)\n",
    "    env.close()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-27T17:30:43.414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening checkpoint file Columns-Genesis-neat-chkpt-dec-1...\n",
      "\n",
      " ****** Running generation 0 ****** \n",
      "\n",
      "Frame 634: Earned 60.0 reward.  Score: 216                        Fitness change: 30156.000\n",
      "Frame 894: Earned 30.0 reward.  Score: 300                        Fitness change: 45210.000\n",
      "Frame 947: Earned 120.0 reward.  Score: 420                        Fitness change: 105210.000\n",
      "Frame 1227: Earned 30.0 reward.  Score: 520                        Fitness change: 120280.000\n",
      "ID:1 S/N: 1 Final frame: 1538               Fitness: 77303578.000 Score: 575\n",
      "                             ****** }}>>>>>ID                   1 GAME OVER after 42.819                   s <<<<<{{ ******\n",
      "Frame 472: Earned 30.0 reward.  Score: 155                        Fitness change: 15125.000\n",
      "Frame 1058: Earned 180.0 reward.  Score: 466                        Fitness change: 105256.000\n",
      "Frame 1236: Earned 30.0 reward.  Score: 516                        Fitness change: 120276.000\n",
      "Frame 1566: Earned 30.0 reward.  Score: 614                        Fitness change: 135344.000\n",
      "Frame 1738: Earned 30.0 reward.  Score: 660                        Fitness change: 150360.000\n",
      "ID:2 S/N: 2 Final frame: 1856               Fitness: 108549624.000 Score: 667\n",
      "                             ****** }}>>>>>ID                   2 GAME OVER after 43.959                   s <<<<<{{ ******\n",
      "Frame 638: Earned 10000.0 reward.  Score: 10143                        Fitness change: 50143.000\n",
      "Frame 767: Earned 30.0 reward.  Score: 10197                        Fitness change: 65167.000\n",
      "Frame 892: Earned 30.0 reward.  Score: 10247                        Fitness change: 80187.000\n",
      "Frame 1285: Earned 30.0 reward.  Score: 10357                        Fitness change: 95267.000\n",
      "Frame 1338: Earned 60.0 reward.  Score: 10417                        Fitness change: 125267.000\n",
      "Frame 1628: Earned 30.0 reward.  Score: 10477                        Fitness change: 140297.000\n",
      "Frame 1745: Earned 30.0 reward.  Score: 10515                        Fitness change: 155305.000\n",
      "ID:3 S/N: 3 Final frame: 1960               Fitness: 137546911.000 Score: 10550\n",
      "                             ****** }}>>>>>ID                   3 GAME OVER after 47.036                   s <<<<<{{ ******\n",
      "Frame 751: Earned 30.0 reward.  Score: 227                        Fitness change: 15197.000\n",
      "Frame 808: Earned 60.0 reward.  Score: 287                        Fitness change: 45197.000\n",
      "Frame 1205: Earned 150.0 reward.  Score: 521                        Fitness change: 120281.000\n",
      "Frame 1531: Earned 60.0 reward.  Score: 643                        Fitness change: 150343.000\n",
      "Frame 1712: Earned 30.0 reward.  Score: 695                        Fitness change: 165365.000\n",
      "ID:4 S/N: 4 Final frame: 2090               Fitness: 148037103.000 Score: 758\n",
      "                             ****** }}>>>>>ID                   4 GAME OVER after 52.770                   s <<<<<{{ ******\n",
      "Frame 523: Earned 30.0 reward.  Score: 161                        Fitness change: 15131.000\n",
      "Frame 962: Earned 90.0 reward.  Score: 346                        Fitness change: 60226.000\n",
      "Frame 1015: Earned 30.0 reward.  Score: 376                        Fitness change: 75226.000\n",
      "Frame 1321: Earned 30.0 reward.  Score: 452                        Fitness change: 90272.000\n",
      "Frame 1502: Earned 30.0 reward.  Score: 508                        Fitness change: 105298.000\n",
      "Frame 1685: Earned 30.0 reward.  Score: 564                        Fitness change: 120324.000\n",
      "ID:5 S/N: 5 Final frame: 1806               Fitness: 83215154.000 Score: 571\n",
      "                             ****** }}>>>>>ID                   5 GAME OVER after 46.215                   s <<<<<{{ ******\n",
      "Frame 446: Earned 30.0 reward.  Score: 131                        Fitness change: 15101.000\n",
      "Frame 828: Earned 10000.0 reward.  Score: 10216                        Fitness change: 65186.000\n",
      "Frame 1144: Earned 30.0 reward.  Score: 10306                        Fitness change: 80246.000\n",
      "Frame 1197: Earned 60.0 reward.  Score: 10366                        Fitness change: 110246.000\n",
      "Frame 1326: Earned 30.0 reward.  Score: 10420                        Fitness change: 125270.000\n",
      "Frame 1379: Earned 120.0 reward.  Score: 10540                        Fitness change: 185270.000\n",
      "Frame 1618: Earned 60.0 reward.  Score: 10628                        Fitness change: 215298.000\n",
      "ID:6 S/N: 6 Final frame: 2226               Fitness: 226973509.000 Score: 10724\n",
      "                             ****** }}>>>>>ID                   6 GAME OVER after 58.464                   s <<<<<{{ ******\n",
      "Frame 638: Earned 10000.0 reward.  Score: 10143                        Fitness change: 50143.000\n",
      "Frame 913: Earned 30.0 reward.  Score: 10239                        Fitness change: 65209.000\n",
      "Frame 1032: Earned 30.0 reward.  Score: 10283                        Fitness change: 80223.000\n",
      "Frame 1297: Earned 30.0 reward.  Score: 10365                        Fitness change: 95275.000\n",
      "Frame 1424: Earned 30.0 reward.  Score: 10413                        Fitness change: 110293.000\n",
      "Frame 1736: Earned 60.0 reward.  Score: 10525                        Fitness change: 140345.000\n",
      "Frame 1972: Earned 30.0 reward.  Score: 10586                        Fitness change: 155376.000\n",
      "Frame 2151: Earned 30.0 reward.  Score: 10636                        Fitness change: 170396.000\n",
      "ID:7 S/N: 7 Final frame: 2346               Fitness: 183740368.000 Score: 10651\n",
      "                             ****** }}>>>>>ID                   7 GAME OVER after 62.530                   s <<<<<{{ ******\n",
      "Frame 617: Earned 30.0 reward.  Score: 203                        Fitness change: 15173.000\n",
      "Frame 1031: Earned 180.0 reward.  Score: 454                        Fitness change: 105244.000\n",
      "Frame 1300: Earned 30.0 reward.  Score: 538                        Fitness change: 120298.000\n",
      "Frame 1815: Earned 30.0 reward.  Score: 670                        Fitness change: 135400.000\n",
      "Frame 1993: Earned 30.0 reward.  Score: 722                        Fitness change: 150422.000\n",
      "Frame 2114: Earned 30.0 reward.  Score: 764                        Fitness change: 165434.000\n",
      "Frame 2234: Earned 30.0 reward.  Score: 806                        Fitness change: 180446.000\n",
      "Frame 2287: Earned 60.0 reward.  Score: 866                        Fitness change: 210446.000\n",
      "ID:8 S/N: 8 Final frame: 2560               Fitness: 226046151.000 Score: 896\n",
      "                             ****** }}>>>>>ID                   8 GAME OVER after 55.423                   s <<<<<{{ ******\n",
      "Frame 738: Earned 30.0 reward.  Score: 221                        Fitness change: 15191.000\n",
      "Frame 791: Earned 60.0 reward.  Score: 281                        Fitness change: 45191.000\n",
      "Frame 912: Earned 30.0 reward.  Score: 327                        Fitness change: 60207.000\n",
      "Frame 1212: Earned 150.0 reward.  Score: 525                        Fitness change: 135255.000\n",
      "Frame 1521: Earned 30.0 reward.  Score: 603                        Fitness change: 150303.000\n",
      "Frame 1650: Earned 90.0 reward.  Score: 717                        Fitness change: 195327.000\n",
      "Frame 1705: Earned 60.0 reward.  Score: 777                        Fitness change: 225327.000\n",
      "Frame 2032: Earned 30.0 reward.  Score: 875                        Fitness change: 240395.000\n",
      "Frame 2323: Earned 30.0 reward.  Score: 937                        Fitness change: 255427.000\n",
      "Frame 2501: Earned 30.0 reward.  Score: 990                        Fitness change: 270450.000\n",
      "ID:9 S/N: 9 Final frame: 2580               Fitness: 307115035.000 Score: 993\n",
      "                             ****** }}>>>>>ID                   9 GAME OVER after 62.931                   s <<<<<{{ ******\n",
      "Frame 774: Earned 10000.0 reward.  Score: 10192                        Fitness change: 50192.000\n",
      "Frame 1162: Earned 30.0 reward.  Score: 10306                        Fitness change: 65276.000\n",
      "Frame 1461: Earned 30.0 reward.  Score: 10381                        Fitness change: 80321.000\n",
      "Frame 1684: Earned 30.0 reward.  Score: 10447                        Fitness change: 95357.000\n",
      "Frame 1838: Earned 30.0 reward.  Score: 10496                        Fitness change: 110376.000\n",
      "Frame 1891: Earned 180.0 reward.  Score: 10676                        Fitness change: 200376.000\n",
      "Frame 1948: Earned 180.0 reward.  Score: 10856                        Fitness change: 290376.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 2003: Earned 240.0 reward.  Score: 11096                        Fitness change: 410376.000\n",
      "Frame 2675: Earned 30.0 reward.  Score: 11227                        Fitness change: 425477.000\n",
      "Frame 2859: Earned 60.0 reward.  Score: 11313                        Fitness change: 468477.000\n",
      "ID:10 S/N: 10 Final frame: 2884               Fitness: 472737110.000 Score: 11313\n",
      "                             ****** }}>>>>>ID                   10 GAME OVER after 65.672                   s <<<<<{{ ******\n",
      "Frame 773: Earned 10000.0 reward.  Score: 10192                        Fitness change: 50192.000\n",
      "Frame 1167: Earned 30.0 reward.  Score: 10306                        Fitness change: 65276.000\n",
      "Frame 1220: Earned 60.0 reward.  Score: 10366                        Fitness change: 95276.000\n",
      "Frame 1273: Earned 90.0 reward.  Score: 10456                        Fitness change: 140276.000\n",
      "Frame 1440: Earned 30.0 reward.  Score: 10498                        Fitness change: 155288.000\n",
      "Frame 1622: Earned 30.0 reward.  Score: 10554                        Fitness change: 170314.000\n",
      "Frame 1751: Earned 30.0 reward.  Score: 10604                        Fitness change: 185334.000\n",
      "Frame 1808: Earned 60.0 reward.  Score: 10664                        Fitness change: 215334.000\n",
      "Frame 1935: Earned 30.0 reward.  Score: 10716                        Fitness change: 230356.000\n",
      "ID:11 S/N: 11 Final frame: 2323               Fitness: 229588007.000 Score: 10787\n",
      "                             ****** }}>>>>>ID                   11 GAME OVER after 52.458                   s <<<<<{{ ******\n",
      "Frame 705: Earned 150.0 reward.  Score: 311                        Fitness change: 75161.000\n",
      "Frame 762: Earned 30.0 reward.  Score: 341                        Fitness change: 90161.000\n",
      "Frame 889: Earned 30.0 reward.  Score: 395                        Fitness change: 105185.000\n",
      "Frame 1016: Earned 30.0 reward.  Score: 445                        Fitness change: 120205.000\n",
      "Frame 1645: Earned 30.0 reward.  Score: 585                        Fitness change: 135315.000\n",
      "ID:12 S/N: 12 Final frame: 1841               Fitness: 131467261.000 Score: 616\n",
      "                             ****** }}>>>>>ID                   12 GAME OVER after 44.256                   s <<<<<{{ ******\n",
      "Frame 996: Earned 210.0 reward.  Score: 449                        Fitness change: 105239.000\n",
      "Frame 1181: Earned 30.0 reward.  Score: 507                        Fitness change: 120267.000\n",
      "Frame 1438: Earned 30.0 reward.  Score: 583                        Fitness change: 135313.000\n",
      "Frame 1757: Earned 30.0 reward.  Score: 671                        Fitness change: 150371.000\n",
      "ID:13 S/N: 13 Final frame: 1939               Fitness: 121218596.000 Score: 690\n",
      "                             ****** }}>>>>>ID                   13 GAME OVER after 41.411                   s <<<<<{{ ******\n",
      "Frame 936: Earned 10000.0 reward.  Score: 10234                        Fitness change: 50234.000\n",
      "ID:14 S/N: 14 Final frame: 1713               Fitness: 39265370.000 Score: 10379\n",
      "                             ****** }}>>>>>ID                   14 GAME OVER after 36.926                   s <<<<<{{ ******\n",
      "Frame 796: Earned 10000.0 reward.  Score: 10191                        Fitness change: 50191.000\n",
      "Frame 1401: Earned 60.0 reward.  Score: 10389                        Fitness change: 80329.000\n",
      "ID:15 S/N: 15 Final frame: 1718               Fitness: 56046549.000 Score: 10436\n",
      "                             ****** }}>>>>>ID                   15 GAME OVER after 34.269                   s <<<<<{{ ******\n",
      "Frame 730: Earned 10000.0 reward.  Score: 10185                        Fitness change: 50185.000\n",
      "Frame 1066: Earned 30.0 reward.  Score: 10293                        Fitness change: 65263.000\n",
      "ID:16 S/N: 16 Final frame: 1188               Fitness: 24982722.000 Score: 10300\n",
      "                             ****** }}>>>>>ID                   16 GAME OVER after 22.033                   s <<<<<{{ ******\n",
      "Frame 844: Earned 90.0 reward.  Score: 300                        Fitness change: 45210.000\n",
      "Frame 1032: Earned 30.0 reward.  Score: 360                        Fitness change: 60240.000\n",
      "ID:17 S/N: 17 Final frame: 1567               Fitness: 40917872.000 Score: 455\n",
      "                             ****** }}>>>>>ID                   17 GAME OVER after 34.078                   s <<<<<{{ ******\n",
      "Frame 621: Earned 10000.0 reward.  Score: 10144                        Fitness change: 50144.000\n",
      "Frame 818: Earned 30.0 reward.  Score: 10216                        Fitness change: 65186.000\n",
      "Frame 1343: Earned 30.0 reward.  Score: 10352                        Fitness change: 80292.000\n",
      "Frame 1589: Earned 60.0 reward.  Score: 10447                        Fitness change: 110327.000\n",
      "Frame 1644: Earned 120.0 reward.  Score: 10567                        Fitness change: 170327.000\n",
      "Frame 1756: Earned 30.0 reward.  Score: 10603                        Fitness change: 185333.000\n",
      "ID:18 S/N: 18 Final frame: 2098               Fitness: 152667218.000 Score: 10659\n",
      "                             ****** }}>>>>>ID                   18 GAME OVER after 52.294                   s <<<<<{{ ******\n",
      "Frame 446: Earned 30.0 reward.  Score: 137                        Fitness change: 15107.000\n",
      "Frame 705: Earned 30.0 reward.  Score: 221                        Fitness change: 30161.000\n",
      "Frame 1083: Earned 10000.0 reward.  Score: 10306                        Fitness change: 80246.000\n",
      "ID:19 S/N: 19 Final frame: 1409               Fitness: 41619791.000 Score: 10367\n",
      "                             ****** }}>>>>>ID                   19 GAME OVER after 33.015                   s <<<<<{{ ******\n",
      "Frame 692: Earned 150.0 reward.  Score: 312                        Fitness change: 75162.000\n",
      "Frame 1073: Earned 30.0 reward.  Score: 408                        Fitness change: 90228.000\n",
      "Frame 1126: Earned 60.0 reward.  Score: 468                        Fitness change: 120228.000\n",
      "Frame 1461: Earned 30.0 reward.  Score: 570                        Fitness change: 135300.000\n",
      "Frame 1571: Earned 30.0 reward.  Score: 606                        Fitness change: 150306.000\n",
      "Frame 1628: Earned 60.0 reward.  Score: 666                        Fitness change: 180306.000\n",
      "ID:20 S/N: 20 Final frame: 1868               Fitness: 140695207.000 Score: 691\n",
      "                             ****** }}>>>>>ID                   20 GAME OVER after 46.825                   s <<<<<{{ ******\n",
      "Frame 846: Earned 10000.0 reward.  Score: 10210                        Fitness change: 50210.000\n",
      "Frame 1107: Earned 30.0 reward.  Score: 10294                        Fitness change: 65264.000\n",
      "Frame 1160: Earned 60.0 reward.  Score: 10354                        Fitness change: 95264.000\n",
      "Frame 1275: Earned 30.0 reward.  Score: 10394                        Fitness change: 110274.000\n",
      "Frame 1328: Earned 60.0 reward.  Score: 10454                        Fitness change: 140274.000\n",
      "ID:21 S/N: 21 Final frame: 1970               Fitness: 123709113.000 Score: 10569\n",
      "                             ****** }}>>>>>ID                   21 GAME OVER after 48.395                   s <<<<<{{ ******\n",
      "Frame 723: Earned 180.0 reward.  Score: 359                        Fitness change: 90179.000\n",
      "Frame 1193: Earned 60.0 reward.  Score: 523                        Fitness change: 120283.000\n",
      "Frame 1246: Earned 120.0 reward.  Score: 643                        Fitness change: 180283.000\n",
      "Frame 1299: Earned 180.0 reward.  Score: 823                        Fitness change: 270283.000\n",
      "ID:22 S/N: 22 Final frame: 1910               Fitness: 223854694.000 Score: 920\n",
      "                             ****** }}>>>>>ID                   22 GAME OVER after 47.858                   s <<<<<{{ ******\n",
      "Frame 620: Earned 10000.0 reward.  Score: 10144                        Fitness change: 50144.000\n",
      "Frame 894: Earned 60.0 reward.  Score: 10270                        Fitness change: 80210.000\n",
      "Frame 1214: Earned 30.0 reward.  Score: 10354                        Fitness change: 95264.000\n",
      "Frame 1571: Earned 30.0 reward.  Score: 10445                        Fitness change: 110325.000\n",
      "ID:23 S/N: 23 Final frame: 1636               Fitness: 80781628.000 Score: 10446\n",
      "                             ****** }}>>>>>ID                   23 GAME OVER after 39.294                   s <<<<<{{ ******\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 777: Earned 10000.0 reward.  Score: 10192                        Fitness change: 50192.000\n",
      "Frame 1438: Earned 30.0 reward.  Score: 10366                        Fitness change: 65336.000\n",
      "ID:24 S/N: 24 Final frame: 1573               Fitness: 42200606.000 Score: 10377\n",
      "                             ****** }}>>>>>ID                   24 GAME OVER after 34.701                   s <<<<<{{ ******\n",
      "Frame 616: Earned 30.0 reward.  Score: 197                        Fitness change: 15167.000\n",
      "Frame 860: Earned 30.0 reward.  Score: 263                        Fitness change: 30203.000\n",
      "Frame 1036: Earned 180.0 reward.  Score: 478                        Fitness change: 120238.000\n",
      "Frame 1241: Earned 30.0 reward.  Score: 550                        Fitness change: 135280.000\n",
      "Frame 1558: Earned 30.0 reward.  Score: 636                        Fitness change: 150336.000\n",
      "Frame 1752: Earned 30.0 reward.  Score: 702                        Fitness change: 165372.000\n",
      "ID:25 S/N: 25 Final frame: 2348               Fitness: 204553672.000 Score: 785\n",
      "                             ****** }}>>>>>ID                   25 GAME OVER after 47.353                   s <<<<<{{ ******\n",
      "Frame 638: Earned 10000.0 reward.  Score: 10162                        Fitness change: 50162.000\n",
      "Frame 816: Earned 30.0 reward.  Score: 10216                        Fitness change: 65186.000\n",
      "ID:26 S/N: 26 Final frame: 1339               Fitness: 43173299.000 Score: 10323\n",
      "                             ****** }}>>>>>ID                   26 GAME OVER after 25.045                   s <<<<<{{ ******\n",
      "Frame 705: Earned 150.0 reward.  Score: 311                        Fitness change: 75161.000\n",
      "Frame 835: Earned 30.0 reward.  Score: 363                        Fitness change: 90183.000\n",
      "Frame 1091: Earned 30.0 reward.  Score: 437                        Fitness change: 105227.000\n",
      "Frame 1265: Earned 30.0 reward.  Score: 485                        Fitness change: 120245.000\n",
      "Frame 1318: Earned 60.0 reward.  Score: 545                        Fitness change: 150245.000\n",
      "Frame 1681: Earned 30.0 reward.  Score: 636                        Fitness change: 165306.000\n",
      "ID:27 S/N: 27 Final frame: 1746               Fitness: 123078312.000 Score: 637\n",
      "                             ****** }}>>>>>ID                   27 GAME OVER after 36.579                   s <<<<<{{ ******\n",
      "Frame 594: Earned 30.0 reward.  Score: 179                        Fitness change: 15149.000\n",
      "Frame 903: Earned 10000.0 reward.  Score: 10246                        Fitness change: 65216.000\n",
      "ID:28 S/N: 28 Final frame: 1353               Fitness: 34174042.000 Score: 10329\n",
      "                             ****** }}>>>>>ID                   28 GAME OVER after 29.820                   s <<<<<{{ ******\n",
      "Frame 524: Earned 30.0 reward.  Score: 155                        Fitness change: 15125.000\n",
      "Frame 716: Earned 30.0 reward.  Score: 219                        Fitness change: 30159.000\n",
      "Frame 899: Earned 30.0 reward.  Score: 275                        Fitness change: 45185.000\n",
      "Frame 1076: Earned 10000.0 reward.  Score: 10310                        Fitness change: 95220.000\n",
      "Frame 1401: Earned 30.0 reward.  Score: 10404                        Fitness change: 110284.000\n",
      "ID:29 S/N: 29 Final frame: 1702               Fitness: 80740375.000 Score: 10445\n",
      "                             ****** }}>>>>>ID                   29 GAME OVER after 35.536                   s <<<<<{{ ******\n",
      "Frame 1048: Earned 150.0 reward.  Score: 414                        Fitness change: 75264.000\n",
      "Frame 1103: Earned 30.0 reward.  Score: 444                        Fitness change: 90264.000\n",
      "Frame 1294: Earned 30.0 reward.  Score: 512                        Fitness change: 105302.000\n",
      "Frame 1347: Earned 60.0 reward.  Score: 572                        Fitness change: 135302.000\n",
      "Frame 1400: Earned 90.0 reward.  Score: 662                        Fitness change: 180302.000\n",
      "Frame 1582: Earned 30.0 reward.  Score: 714                        Fitness change: 195324.000\n",
      "Frame 1902: Earned 60.0 reward.  Score: 830                        Fitness change: 225380.000\n",
      "Frame 2191: Earned 30.0 reward.  Score: 894                        Fitness change: 240414.000\n",
      "Frame 2437: Earned 30.0 reward.  Score: 965                        Fitness change: 255455.000\n"
     ]
    }
   ],
   "source": [
    "######## Major parameter specifications ########\n",
    "\n",
    "# specify game to load with its config file (comment/uncomment as appropriate)\n",
    "game, state, config_file = 'Columns-Genesis', 'Arcade.Easy.Level0', 'config-Columns-Decisive'\n",
    "\n",
    "# specify checkpoint file if necessary as a string ('0' if not to be used)\n",
    "chkpt = '0'\n",
    "# specify checkpoint index manually\n",
    "# chkpt_index = 1\n",
    "# chkpt = game + '-neat-chkpt-dec-'+ str(chkpt_index)\n",
    "\n",
    "# specify type of retro environment observation space via index of below list\n",
    "input_type_index = 0 \n",
    "# specify observation type\n",
    "input_types = [retro.Observations.IMAGE, retro.Observations.RAM]\n",
    "\n",
    "######## END Major parameter specifications ########\n",
    "\n",
    "# create the retro environment for the chosen game, including starting state\n",
    "env = retro.make(game,state,obs_type=input_types[input_type_index],\n",
    "                 use_restricted_actions=retro.Actions.ALL          )\n",
    "\n",
    "# restore the checkpoint if specified\n",
    "if chkpt != '0':\n",
    "    print(f\"Opening checkpoint file {chkpt}...\")\n",
    "    p = neat.Checkpointer.restore_checkpoint(chkpt)\n",
    "\n",
    "# load in the configuration for the NEAT algorithm...\n",
    "config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction, \n",
    "                     neat.DefaultSpeciesSet, neat.DefaultStagnation, config_file)\n",
    "    \n",
    "# ... and create the NEAT population with the above specified configuration\n",
    "pop = neat.Population(config)\n",
    "\n",
    "# prepare statistics reporting    \n",
    "pop.add_reporter(neat.StdOutReporter(True))\n",
    "\n",
    "stats = neat.StatisticsReporter()\n",
    "\n",
    "pop.add_reporter(stats)\n",
    "\n",
    "# and create checkpoint file as things progress\n",
    "pop.add_reporter(neat.Checkpointer(generation_interval = 1, \n",
    "                                 time_interval_seconds = 300,\n",
    "                                 filename_prefix = game + '-neat-chkpt-dec-'))\n",
    "\n",
    "# set about the evolution process\n",
    "winner = pop.run(eval_genomes)\n",
    "\n",
    "# pickle the final result\n",
    "with open(game+'-winner.pkl', 'wb') as output:\n",
    "    pickle.dump(winner, output, 1)\n",
    "\n",
    "# close the render window when finished\n",
    "try:\n",
    "    env.render(close=True)\n",
    "    env.close()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
