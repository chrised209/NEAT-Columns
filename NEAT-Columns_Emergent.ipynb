{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code allows the neuroevolution agent's behavior to develop in a more \"emergent\" way, giving the neural network direct control over the button presses in the game environment (with a little help to get out of infinite loops).  \n",
    "\n",
    "This approach is quite clearly inferior to the 'decisive' model when considering time to reach each score, but can on rare occasions lead to semi-sensible play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-27T17:28:49.523Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## %matplotlib auto\n",
    "# import relevant libraries\n",
    "import retro, numpy as np, cv2, neat, pickle, time, random, warnings\n",
    "from scipy.ndimage.measurements import label as sp_label\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "random.seed(12345)\n",
    "\n",
    "######## Begin eval_genomes function ########\n",
    "def eval_genomes(genomes, config, shrink=8, render=False):\n",
    "    # initialize genome counter, set popul_size to match pop_size in config\n",
    "    genome_counter, popul_size = 1 , 100\n",
    "    # define timeout frame counter limit\n",
    "    counter_limit = 5000\n",
    "    # define empty input array to feed neural net\n",
    "    imgarray = []\n",
    "    # shot pacing vector (not needed for Columns)\n",
    "    shot = [0,0,1]\n",
    "    # reset the environment to initialize gym retro\n",
    "    ob = env.reset()\n",
    "    # color mapping to improve contrast and homogenize colors\n",
    "    colors = np.array([192,156,138,62,166,90,92,46,128,121,69,59])\n",
    "    new_colors = np.array([202,202,172,172,142,142,112,112,82,82,52,52])\n",
    "    # initialize the display mapping array\n",
    "    reshade_map = np.zeros(256,dtype=ob.dtype) \n",
    "    # populate the display mapping array\n",
    "    reshade_map[colors] = new_colors\n",
    "    reshade_map = reshade_map + np.roll(reshade_map, 1) \n",
    "#     print(reshade_map)\n",
    "    # define valid connections for column labeling\n",
    "    c_valid_conns = np.array((0,1,0,0,1,0,0,1,0,), dtype=np.int).reshape((3,3))\n",
    "    # define valid connections for island labeling\n",
    "    i_valid_conns = np.append(np.append(np.zeros(9),np.ones(9)),np.zeros(9)).reshape(3,3,3)\n",
    "    # initialize index array for color-broadcasted game state\n",
    "    ind_grid = np.indices((7,13,6))\n",
    "\n",
    "    # for each member of the population\n",
    "    for genome_id, genome in genomes:\n",
    "        # generate the sequence id in the current generation\n",
    "        genome_in_gen = genome_counter%popul_size\n",
    "        # create the neural net\n",
    "        net = neat.nn.recurrent.RecurrentNetwork.create(genome, config)\n",
    "        # initialize a few tracking variables\n",
    "        fitness, counter, frame = 0, 0, 0\n",
    "        # column height initial state (explained below)\n",
    "        col_hts_i   = np.zeros(6)\n",
    "        # initialize island size distribution\n",
    "        isle_sizes_i = np.array(0)\n",
    "        # initialize being done as false\n",
    "        done = False\n",
    "        # specify a random input on the virtual controller\n",
    "        ac = env.action_space.sample()\n",
    "        # reset the environment\n",
    "        ob = env.reset()\n",
    "        # define the dimension lengths of the screen output (x, y, color)\n",
    "        img_x, img_y, img_c = env.observation_space.shape\n",
    "#         # print the raw dimensions\n",
    "#         print(f'RAW - X size: {img_x}   Y size: {img_y}   Colors: {img_c}')\n",
    "        # define the cropped region boundaries and shrink factor\n",
    "        # dims legend: y0, h, x0, w\n",
    "        dims = [8, 208, 16, 96]\n",
    "        # use a list comprehension to calculate the pre-drop scaled dims\n",
    "        sc_dims = [int(i/shrink) for i in dims]\n",
    "#         print(f'Cropped and rescaled (pre-drop): \\nX offset: {sc_dims[2]}   Y offset: {sc_dims[0]}   \\\n",
    "#               width: {sc_dims[3]}   height: {sc_dims[1]}')\n",
    "        # make an OpenCV window\n",
    "        cv2.namedWindow('What the neural net sees', cv2.WINDOW_NORMAL)\n",
    "        # begin tracking of cycle time\n",
    "        start_time = time.time()\n",
    "        # while done is not True\n",
    "        while not done:           \n",
    "            # open a render window to follow the action if requested\n",
    "            if render == True:\n",
    "                env.render()\n",
    "            # increment the frame counter\n",
    "            frame += 1\n",
    "            # print render time\n",
    "#             print('Frame', frame, 'render', time.time() - start_time, 's'); start_time = time.time()    \n",
    "\n",
    "            # prepare a scaled image for rendering of final observation\n",
    "            # apply color conversion (quirk of OpenCV)\n",
    "            input_img  = cv2.cvtColor(ob, cv2.COLOR_BGR2GRAY)\n",
    "#             if frame == 1:\n",
    "#                 print(f'initial input_img: {input_img.shape}')\n",
    "            # crop the image via NumPy slicing (dims indices defined above)\n",
    "            input_img = input_img[dims[0]:dims[0]+dims[1], dims[2]:dims[2]+dims[3]]\n",
    "#             if frame == 1:\n",
    "#                 print(f'cropped input_img: {input_img.shape}')\n",
    "            input_img  = cv2.resize(input_img, (int((sc_dims[3])/2), int(sc_dims[1])))\n",
    "#             if frame == 1:\n",
    "#                 print(f'final input_img: {input_img.shape}')\n",
    "            # remap the colors to homogenize the jewel colorings\n",
    "            resh_img = reshade_map[input_img]\n",
    "            # throw out the now-unnecessary y-resolution\n",
    "            resc_img = resh_img[::2]      \n",
    "#             print(resc_img)\n",
    "            # display the (rastered) observation space as NEAT model sees it\n",
    "            cv2.imshow('What the neural net sees', resc_img)\n",
    "            cv2.waitKey(1)   \n",
    "            # build the input to the neural net\n",
    "            imgarray = np.ravel(resc_img)\n",
    "            # match range of colors to range of label outputs\n",
    "            unit_img = np.where(resc_img == 0, 0,(resc_img-22)/30)\n",
    "            \n",
    "            #evaluate column height and isle average adjustments only after frame 8\n",
    "#             if frame > 0:\n",
    "\n",
    "######## column height penalty calculation ########\n",
    "            # c_ncomponents is a simple count of the conected columns in labeled\n",
    "            columns, c_ncomponents = sp_label(unit_img, c_valid_conns)\n",
    "#                 print(columns)\n",
    "            # throw out the falling block with .isin(x,x[-1]) combined with... \n",
    "            # the mask nonzero(x) \n",
    "            drop_falling = np.isin(columns, columns[-1][np.nonzero(columns[-1])])\n",
    "            col_hts = drop_falling.sum(axis=0)\n",
    "#                 print(f'col_hts {col_hts}')\n",
    "            # calculate differentials for the (grounded) column heights\n",
    "            d_col_hts = np.sum(col_hts - col_hts_i)\n",
    "#                 print(f'col_hts {col_hts} - col_hts_i {col_hts_i} ===> d_col_hts {d_col_hts}')\n",
    "            # set col_hts_i to current col_hts for next evaluation\n",
    "            col_hts_i = col_hts\n",
    "            # calculate penalty/bonus function\n",
    "#                 col_pen = (col_hts**4 - 3**4).sum()\n",
    "            col_pen = np.where(d_col_hts > 0, (col_hts**4 - 3**4), 0).sum()\n",
    "#                 \n",
    "#             if col_pen !=0:\n",
    "#                 print(f'col_pen: {col_pen}')\n",
    "######## end column height penalty calculation ########\n",
    "\n",
    "######## color island bonus calculation ########\n",
    "            # mask the unit_img to remove the falling block\n",
    "            isle_img = drop_falling * unit_img\n",
    "#             print(isle_img)\n",
    "            # broadcast the game board to add a layer for each color\n",
    "            isle_imgs = np.broadcast_to(isle_img,(7,*isle_img.shape))\n",
    "            # define a mask to discriminate on color in each layer\n",
    "            isle_masked = isle_imgs*[isle_imgs==ind_grid[0]]\n",
    "            # reshape the array to return to 3 dimensions\n",
    "            isle_masked = isle_masked.reshape(isle_imgs.shape)\n",
    "            # generate the isle labels\n",
    "            isle_labels, isle_ncomps = sp_label(isle_masked, i_valid_conns)\n",
    "            # determine the island sizes (via return_counts) for all the unique labels\n",
    "            isle_inds, isle_sizes = np.unique(isle_labels, return_counts=True)\n",
    "            # zero out isle_sizes[0] to remove spike for background (500+ for near empty board)\n",
    "            isle_sizes[0] = 0\n",
    "            # evaluate difference to determine whether bonus applies\n",
    "            if isle_sizes_i.sum() != isle_sizes.sum():\n",
    "            # calculate bonus for all island sizes ater throwing away the 0 count\n",
    "                isle_bonus = (isle_sizes**3).sum()\n",
    "            else:\n",
    "                isle_bonus = 0\n",
    "#             if isle_bonus != 0:\n",
    "#                 print(f'isle_bonus:{isle_bonus} isle_avgs_i: {isle_sizes_i.sum()}  isle_avgs {isle_sizes.sum()}')\n",
    "            # update the size distribution from the previous frame\n",
    "            isle_sizes_i = isle_sizes\n",
    "######## color island bonus calculation ########\n",
    "\n",
    "            # let the neural net do its thing on the input imgarray and generate \n",
    "            # the next action every eighth frame\n",
    "#             if frame % 3 == 1:\n",
    "            nnOutput = net.activate(imgarray)\n",
    "#             print('Frame', frame, 'NN output:', nnOutput)\n",
    "#             print('nn', time.time() - start_time, 's'); start_time = time.time()\n",
    "            output_threshold = 0.5\n",
    "            step_threshed = list(map(lambda x : 1 if x > output_threshold else 0, nnOutput))\n",
    "            if counter == 100:\n",
    "                # get out of the infinite loop by pressing down once\n",
    "                stepInput = [0, 0, 0, 0,\n",
    "                             0, 1, 0, 0,\n",
    "                             0, 0, 0, 0 ]\n",
    "                # and then reset the counter\n",
    "                counter = 0\n",
    "            else:\n",
    "                stepInput = [step_threshed[0], 0, 0, 0,\n",
    "                             0,                step_threshed[1],\n",
    "                             step_threshed[2], step_threshed[3],\n",
    "                             0, step_threshed[4], 0, 0          ]\n",
    "#             print('env step input:', stepInput)\n",
    "#             print('env step:', time.time() - start_time, 's'); start_time = time.time()\n",
    "                \n",
    "            # feed the neural net output to the emulator\n",
    "            ob, rew, done, info = env.step(stepInput)\n",
    "\n",
    "            # when removing gems:\n",
    "            if (rew > 1) and (rew != 10000):\n",
    "                # apply scaled reward to fitness \n",
    "                fitness += rew * 500\n",
    "            # when wildcard/magic block hits bottom:\n",
    "            elif rew == 10000:\n",
    "                # apply scaled reward to fitness\n",
    "                fitness += rew * 5\n",
    "            # when pressing down to simply speed play:\n",
    "            else:    \n",
    "                # apply raw reward to fitness only when the net does so naturally             \n",
    "                if counter != 100:\n",
    "                    fitness += rew    \n",
    "            # apply column penalty to fitness\n",
    "            fitness -= float(col_pen) * 0.2\n",
    "            # apply scaled isle creation bonus to fitness\n",
    "            fitness += float(isle_bonus) * 30\n",
    "            # when a score is made\n",
    "            if rew >= 1:\n",
    "                # reset the counter\n",
    "                counter = 0\n",
    "#               # print out the variables \n",
    "            # when a reward is earned...\n",
    "            if rew >= 30:\n",
    "                # ... give status update\n",
    "                print(f\"Frame {frame}: Earned {rew} reward. Fitness: {fitness:0.3f}\")\n",
    "#             elif rew == 1:\n",
    "#                 pass\n",
    "            else:\n",
    "                counter +=1\n",
    "            # every 1000 frames or so\n",
    "#             if frame%9 == 8:\n",
    "                  # display island bonus and column penalty contributions to fitness\n",
    "              \n",
    "              # provide time benchmark...\n",
    "#             print(f\"End Frame {frame-9}-{frame} cycle: {(time.time() - start_time):.3f} s  Fitness: {fitness:0.3f}\"); start_time = time.time()\n",
    "#                 # ... and give status update\n",
    "#                 print(f'Reward: {rew} Counter: {counter} Fitness: {fitness:0.3f}')\n",
    "            # if the reward drought is too severe\n",
    "            if counter > counter_limit:\n",
    "                # indicate such\n",
    "                print(f'*** Counter limit reached at frame {frame} ***' )\n",
    "                # and abort the run\n",
    "                done = True\n",
    "            # at the end of the game\n",
    "            if done:\n",
    "                # print out the high-level results...\n",
    "                print(f\"ID:{genome_id} ({genome_in_gen}/{popul_size}) Final frame: {frame} Fitness: {fitness:0.3f} Score: {info['score']} \")\n",
    "                # ... and the game over indicator\n",
    "                if counter <= counter_limit:\n",
    "                    print(f'                                        ****** }}}}>>>>>ID {genome_id} GAME OVER after {(time.time() - start_time):.3f} s <<<<<{{{{ ******')\n",
    "                # record final fitness \n",
    "                genome.fitness = fitness\n",
    "        # iterate genome counter\n",
    "        genome_counter += 1\n",
    "#         return fitness\n",
    "# close any lingering environment if necessary            \n",
    "try:\n",
    "    env.close()\n",
    "except:\n",
    "    pass\n",
    "######## END eval_genomes function ########\n",
    "\n",
    "######## Major parameter specifications ########\n",
    "\n",
    "# specify game to load with its config file (comment/uncomment as appropriate)\n",
    "game, state, config_file = 'Columns-Genesis', 'Arcade.Easy.Level0', 'config-Columns-emergent'\n",
    "\n",
    "# specify checkpoint file if necessary as a string ('0' if not to be used)\n",
    "# chkpt = '0'\n",
    "# specify checkpoint index manually\n",
    "chkpt_index = 12\n",
    "chkpt = game + '-neat-chkpt-cp-'+ str(chkpt_index)\n",
    "\n",
    "# specify type of retro environment observation space via index of below list\n",
    "input_type_index = 0 \n",
    "# specify observation type\n",
    "input_types = [retro.Observations.IMAGE, retro.Observations.RAM]\n",
    "\n",
    "######## END Major parameter specifications ########\n",
    "\n",
    "\n",
    "\n",
    "# create the retro environment for the chosen game, including starting state\n",
    "env = retro.make(game,state,obs_type=input_types[input_type_index],use_restricted_actions=retro.Actions.ALL            )\n",
    "    \n",
    "# restore the checkpoint if specified\n",
    "if chkpt != '0':\n",
    "    print(f\"Opening checkpoint file {chkpt}...\")\n",
    "    p = neat.Checkpointer.restore_checkpoint(chkpt)\n",
    "else:\n",
    "    # otherwise, load in the configuration for the NEAT algorithm\n",
    "    config = neat.Config(neat.DefaultGenome,neat.DefaultReproduction,neat.DefaultSpeciesSet,neat.DefaultStagnation,config_file)\n",
    "    \n",
    "    # and create the NEAT population with the above specified configuration\n",
    "    p = neat.Population(config)\n",
    "\n",
    "# prepare statistics reporting    \n",
    "p.add_reporter(neat.StdOutReporter(True))\n",
    "\n",
    "stats = neat.StatisticsReporter()\n",
    "\n",
    "p.add_reporter(stats)\n",
    "\n",
    "# and create checkpoint file as things progress\n",
    "p.add_reporter(neat.Checkpointer(generation_interval = 1, \n",
    "                                 time_interval_seconds = 300,\n",
    "                                 filename_prefix = game + '-neat-chkpt-cp-'))\n",
    "\n",
    "\n",
    "# set about the evolution process\n",
    "winner = p.run(eval_genomes)\n",
    "\n",
    "######## ParallelEvaluator not passing attributes correctly\n",
    "# or run in parallel by creating a parallel evaluator instance and using its .evaluate()\n",
    "# p_e = neat.ParallelEvaluator(4, eval_genomes)\n",
    "\n",
    "# winner = p.run(p_e.evaluate)\n",
    "                      \n",
    "                      \n",
    "# close the render window when finished\n",
    "try:\n",
    "    env.render(close=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# pickle the final result\n",
    "with open(game+'-winner.pkl', 'wb') as output:\n",
    "    pickle.dump(winner, output, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
